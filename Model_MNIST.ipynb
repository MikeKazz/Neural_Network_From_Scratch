{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPizwT9/H0b6sz7gtX6mUHx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehrdadkazemi254/Neural_Network_From_Scratch/blob/main/Model_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "zq-nBS8evC4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "FNeSAvTbiYIh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[0:5000, :]\n",
        "X_test = X_test[0:500, :]\n",
        "y_train = y_train[0:5000]\n",
        "y_test = y_test[0:500]\n",
        "image_vector_size = 28*28\n",
        "X_train = X_train.reshape(X_train.shape[0], image_vector_size)\n",
        "X_test = X_test.reshape(X_test.shape[0], image_vector_size)"
      ],
      "metadata": {
        "id": "xMalyxdGkJYu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" X_train shape: {X_train.shape}\")\n",
        "print(f\" y_train shape: {y_train.shape}\")\n",
        "print(f\" X_test shape: {X_test.shape}\")\n",
        "print(f\" y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzQBDF12mPQ-",
        "outputId": "03f8b7d1-5b40-4969-e3b4-de68c8bb436e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " X_train shape: (5000, 784)\n",
            " y_train shape: (5000,)\n",
            " X_test shape: (500, 784)\n",
            " y_test shape: (500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the and y axis for plotting\n",
        "cost_y = []\n",
        "iteration_X = []"
      ],
      "metadata": {
        "id": "x4ZcpR66t-Ac"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The model"
      ],
      "metadata": {
        "id": "y1okwD2tvHcH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "tyUfKLnihcS4"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork():\n",
        "    def __init__(self, X, y):\n",
        "        #m : number of images\n",
        "        self.m = X.shape[0]\n",
        "        #n : number of features in our data (784)\n",
        "        self.n = X.shape[1]\n",
        "        #h1 : size of the first hidden layer\n",
        "        self.h1 = 25\n",
        "        #h2 : number of nodes in output (10 digits)\n",
        "        self.h2 = 10\n",
        "        #learning rate\n",
        "        self.learning_rate = 1e-3\n",
        "\n",
        "    def initialize_weights(self, l0, l1):\n",
        "        #l0: the number of nodes it is coming from\n",
        "        #l1: the number of nodes it is going to\n",
        "        w = np.random.randn(l0, l1) * 0.01\n",
        "        b = np.zeros((1, l1))\n",
        "        return w, b\n",
        "\n",
        "    def forward_prop(self, X, parameters): #parameters is a dictionary that stores all the necessary weights and biases\n",
        "        W2 = parameters['W2']  #from the hidden layer 1 to 2\n",
        "        W1 = parameters['W1']  #from the input to the hidden layer 1\n",
        "        b1 = parameters['b1']\n",
        "        b2 = parameters['b2']\n",
        "\n",
        "        #forward prop\n",
        "        a0 = X\n",
        "        z1 = np.dot(a0, W1) + b1\n",
        "        a1 = np.maximum(0, z1) #ReLU activation function\n",
        "        z2 = np.dot(a1, W2) + b2\n",
        "\n",
        "        #softmax\n",
        "        scores = z2\n",
        "        exp_scores = np.exp(scores)\n",
        "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "        cache = {'a0': X, 'probs': probs, 'a1': a1}\n",
        "        return cache, probs\n",
        "\n",
        "    def compute_cost(self, y, probs, parameters): #cross entropy loss\n",
        "        W1 = parameters['W1']\n",
        "        W2 = parameters['W2']\n",
        "\n",
        "        loss = -np.log(probs[np.arange(self.m),y])\n",
        "        avg_loss = np.sum(loss) / self.m\n",
        "\n",
        "        return avg_loss\n",
        "\n",
        "    def back_prop(self, cache, parameters, y):\n",
        "        #unpack parameters\n",
        "        W2 = parameters['W2']\n",
        "        W1 = parameters['W1']\n",
        "        b1 = parameters['b1']\n",
        "        b2 = parameters['b2']\n",
        "\n",
        "        #unpack from forward prop\n",
        "        a0 = cache['a0']\n",
        "        a1 = cache['a1']\n",
        "        probs = cache['probs']\n",
        "\n",
        "        #we want dW1, dW2, db1, db2\n",
        "        dz2 = probs\n",
        "        dz2[np.arange(self.m), y] -= 1\n",
        "        dz2 /= self.m\n",
        "\n",
        "        #backprop to dW2, db2\n",
        "        dW2 = np.dot(a1.T, dz2)\n",
        "        db2 = np.sum(dz2, axis=0, keepdims=True)\n",
        "\n",
        "        dz1 = np.dot(dz2, W2.T)\n",
        "        dz1 = dz1 * (a1 > 0)\n",
        "\n",
        "        dW1 = np.dot(a0.T, dz1)\n",
        "        db1 = np.sum(dz1, axis=0, keepdims=True)\n",
        "\n",
        "        grads = {'dW1': dW1, 'dW2': dW2, 'db1': db1, 'db2': db2}\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def update_parameters(self, parameters, grads):\n",
        "        #gradient descent step\n",
        "        W2 = parameters['W2']\n",
        "        W1 = parameters['W1']\n",
        "        b1 = parameters['b1']\n",
        "        b2 = parameters['b2']\n",
        "\n",
        "        dW1 = grads['dW1']\n",
        "        dW2 = grads['dW2']\n",
        "        db1 = grads['db1']\n",
        "        db2 = grads['db2']\n",
        "\n",
        "        W2 -= self.learning_rate * dW2\n",
        "        W1 -= self.learning_rate * dW1\n",
        "        b2 -= self.learning_rate * db2\n",
        "        b1 -= self.learning_rate * db1\n",
        "\n",
        "        parameters = {'W1': W1, 'W2': W2, 'b1': b1, 'b2': b2}\n",
        "        return parameters\n",
        "\n",
        "    def main(self, X, y, num_iter=1000):\n",
        "        W1, b1 = self.initialize_weights(self.n, self.h1)\n",
        "        W2, b2 = self.initialize_weights(self.h1, self.h2)\n",
        "\n",
        "        parameters = {'W1': W1, 'W2': W2, 'b1': b1, 'b2': b2}\n",
        "      \n",
        "        for it in range(num_iter + 1):\n",
        "            #forward prop\n",
        "            cache, probs = self.forward_prop(X, parameters)\n",
        "\n",
        "            #calculate cost\n",
        "            cost = self.compute_cost(y, probs, parameters)\n",
        "\n",
        "            if it % 100 == 0:\n",
        "                print(f\"At iteration {it}, we have a Loss of {cost}\")\n",
        "\n",
        "            grads = self.back_prop(cache, parameters, y)\n",
        "\n",
        "            #update parameters\n",
        "            parameters = self.update_parameters(parameters, grads)\n",
        "            cost_y.append(cost)\n",
        "            iteration_X.append(it)\n",
        "        return parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "UEZmbVKcvMEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NN = NeuralNetwork(X_train, y_train)\n",
        "trained_parameters = NN.main(X_train, y_train, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZPa8rQqiN3O",
        "outputId": "03512ba8-c37d-4ac5-cdda-e3fa47240af8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At iteration 0, we have a Loss of 2.7280680809274593\n",
            "At iteration 100, we have a Loss of 0.377862788392031\n",
            "At iteration 200, we have a Loss of 0.2741571811694135\n",
            "At iteration 300, we have a Loss of 0.22392932262773665\n",
            "At iteration 400, we have a Loss of 0.1905708423263292\n",
            "At iteration 500, we have a Loss of 0.16568252846679377\n",
            "At iteration 600, we have a Loss of 0.14578265070370394\n",
            "At iteration 700, we have a Loss of 0.1289728606703809\n",
            "At iteration 800, we have a Loss of 0.1145044423195986\n",
            "At iteration 900, we have a Loss of 0.10182242117250487\n",
            "At iteration 1000, we have a Loss of 0.09054805258167928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting"
      ],
      "metadata": {
        "id": "vQ5SYW-9vOwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(iteration_X, cost_y)\n",
        "plt.xlabel('Iteration', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.savefig('learning.jpg', dpi=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "UDrc8ZUItPju",
        "outputId": "db6e0a89-95a3-4117-f19b-3e6cd6f26442"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prediction and accuracy"
      ],
      "metadata": {
        "id": "UeJfG7VgvRI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = trained_parameters['W2']\n",
        "W1 = trained_parameters['W2']\n",
        "b2 = trained_parameters['b2']\n",
        "b1 = trained_parameters['b1']"
      ],
      "metadata": {
        "id": "ncMUNJb3nBcF"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run forward propogation with trained parameters on X_test\n",
        "_, probs = NN.forward_prop(X_test, trained_parameters)\n",
        "y_pred = np.argsort(probs, axis=1)[:, -1]"
      ],
      "metadata": {
        "id": "kD2O-xporaZo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.sum((y_pred == y_test)) / y_pred.shape[0]\n",
        "print(f\"The accuracy of our model is {accuracy*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSUj9G6PrpK1",
        "outputId": "c45cf673-1790-4b63-dd51-cf6c195f5f3a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of our model is 92.0%\n"
          ]
        }
      ]
    }
  ]
}